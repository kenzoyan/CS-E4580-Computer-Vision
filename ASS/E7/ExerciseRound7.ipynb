{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true;\n",
       "function code_toggle() {\n",
       "if (code_show){\n",
       "$('div.input').hide();\n",
       "} else {\n",
       "$('div.input').show();\n",
       "}\n",
       "code_show = !code_show\n",
       "}\n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is used for creating a button that hides/unhides code cells to quickly look only the results.\n",
    "# Works only with Jupyter Notebooks.\n",
    "\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n",
      "Data stored in /coursedata/exercise-07-data\n"
     ]
    }
   ],
   "source": [
    "# Description:\n",
    "#   Exercise7 notebook.\n",
    "#\n",
    "# Copyright (C) 2018 Santiago Cortes, Juha Ylioinas\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "# Preparations\n",
    "import numpy as np\n",
    "\n",
    "# Select data directory\n",
    "if os.path.isdir('/coursedata'):\n",
    "    # JupyterHub\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../../../coursedata'):\n",
    "    # Local installation\n",
    "    course_data_dir = '../../../coursedata'\n",
    "else:\n",
    "    # Docker\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-07-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 7\n",
    "The problems should be solved before the exercise session and solutions returned via\n",
    "MyCourses. <br><br> For this exercise round, upload this notebook(pdf and .ipynb versions) containing your source codes (for Exercise 1) and your answer to the question of Exercise2, and all the answers to the questions of Exercise 3 (VGG practical), see part[1-3].ipynb. Note that it's not necessary to upload part1.ipynb, part2.ipynb or part3.ipynb, because all of the necessary questions related to them are contained in this notebook and you're not expected to do any coding in Exercises 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Comparing  bags-of-words  with  tf-idf  weighting\n",
    "Assume  that  we  have  an  indexed  collection  of  documents  containing  the  five  terms  of the following table where the second row indicates the percentage of documents in which each term appears.<br>\n",
    "\n",
    "| term | cat | dog |mammals | mouse | pet |\n",
    "| --- | :---: | :---: | :---: | :---: | :---: |\n",
    "| **% of documents** | 5 | 20 | 2 | 10 | 60 |\n",
    "\n",
    "Now, given the query $Q=\\{mouse, cat, pet, mammals\\}$, compute the similarity between $Q$ and the following example documents $D1$, $D2$, $D3$, by using the cosine similarity measure and tf-idf weights (i.e. term frequency - inverse document frequency) for the bag-of-words histogram representations of the documents and the query.\n",
    "\n",
    "-  $D1$ = Cat is a pet, dog is a pet, and mouse may be a pet too.\n",
    "-  $D2$ = Cat, dog and mouse are all mammals.\n",
    "-  $D3$ = Cat and dog get along well, but cat may eat a mouse.\n",
    "\n",
    "Ignore other words except the five terms. You may proceed with the following steps:\n",
    "\n",
    "a) Compute and report the inverse document frequency (idf) for each of the five terms. Use the logarithm with base 2. (idf is the logarithm on slide 69 of Lecture 6.)<br>\n",
    "b) Compute the term frequencies for the query and each document. <br>\n",
    "c) Form the tf-idf weighted word occurrence histograms for the query and documents. <br>\n",
    "d) Evaluate the cosine similarity between the query and each document (i.e.\\ normalized scalar product between the weighted occurrence histograms as shown on slide 45).<br> \n",
    "e) Report the relative ranking of the documents. (You should get similarities 0.95, 0.64, and 0.63, but you need to determine which corresponds to which document.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.32192809 2.32192809 5.64385619 3.32192809 0.73696559]\n",
      "      cat     dog  mammals   mouse   pet\n",
      "0  0.2500  0.0000   0.2500  0.2500  0.25\n",
      "1  0.0667  0.0667   0.0000  0.0667  0.20\n",
      "2  0.1429  0.1429   0.1429  0.1429  0.00\n",
      "3  0.1667  0.0833   0.0000  0.0833  0.00\n"
     ]
    }
   ],
   "source": [
    "## Comparing  bags-of-words  with  tf-idf  weighting\n",
    "##--your-code-starts-here--##\n",
    "\n",
    "# terms={\"cat\":0.05,\"dog\":0.2,\"mammals\":0.02,\"mouse\":0.01,\"pet\":0.6}\n",
    "terms=[0.05,0.2,0.02,0.1,0.6]\n",
    "idf=np.array([math.log((1.0/i),2) for i in terms])\n",
    "\n",
    "\n",
    "print(idf)\n",
    "\n",
    "\n",
    "words=[\"cat\",\"dog\",\"mammals\",\"mouse\",\"pet\"]\n",
    "\n",
    "q=\"cat mammals mouse pet\"\n",
    "d1=\"cat is a pet dog is a pet and mouse may be a pet too\"\n",
    "d2= \"cat dog and mouse are all mammals\"\n",
    "d3 = \"cat and dog get along well but cat may eat a mouse\"\n",
    "\n",
    "def computeTF(text):\n",
    "    w=text.split()\n",
    "    counts=len(w)\n",
    "    dicts=collections.Counter(w)\n",
    "#     print(counts)\n",
    "#     print(dicts)\n",
    "    tf=[]\n",
    "    for i in words:\n",
    "        tf.append(round((dicts[i]/float(counts)),4))\n",
    "        \n",
    "    return np.array(tf)\n",
    "        \n",
    "tfs=np.concatenate((computeTF(q),computeTF(d1),computeTF(d2),computeTF(d3))).reshape((-1,5))\n",
    "# print(tfs)\n",
    "\n",
    "tf_df=pd.DataFrame(tfs,columns=[\"cat\",\"dog\",\"mammals\",\"mouse\",\"pet\"])\n",
    "print(tf_df)\n",
    "\n",
    "##--your-code-ends-here--##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf=[]\n",
    "\n",
    "tfidf.append(np.array(tf_df.cat)*idf[0])\n",
    "tfidf.append(np.array(tf_df.dog)*idf[1])\n",
    "tfidf.append(np.array(tf_df.mammals)*idf[2])\n",
    "tfidf.append(np.array(tf_df.mouse)*idf[3])\n",
    "tfidf.append(np.array(tf_df.pet)*idf[4])\n",
    "\n",
    "\n",
    "tfidf=np.array(tfidf)\n",
    "\n",
    "docslabel=['q','d1','d2','d3']\n",
    "\n",
    "size = 4\n",
    "index = np.arange(size)\n",
    "total_width, n = 0.8, 5\n",
    "width = total_width / n\n",
    "index = index - (total_width - width) / 2\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(5):\n",
    "    if i==2:\n",
    "        plt.bar(index+i*width, tfidf[i], width=width, label=words[i], tick_label=docslabel)\n",
    "    else:\n",
    "        plt.bar(index+i*width, tfidf[i], width=width, label=words[i])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.08048202, 0.2882726 , 0.61760352, 0.72046541],\n",
       "       [0.        , 0.1548726 , 0.33180352, 0.19341661],\n",
       "       [1.41096405, 0.        , 0.80650705, 0.        ],\n",
       "       [0.83048202, 0.2215726 , 0.47470352, 0.27671661],\n",
       "       [0.1842414 , 0.14739312, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities Rank: [1 2 0]\n",
      "Similarities: [0.95469481 0.64317528 0.62890671]\n"
     ]
    }
   ],
   "source": [
    "def Similarity(q,docs):\n",
    "    evaluation=np.array([np.sum(q*d)/(np.sqrt(np.sum(q**2))*np.sqrt(np.sum(d**2))) for d in docs])\n",
    "    srtArg= np.argsort(evaluation)[::-1]\n",
    "    srt = np.sort(evaluation)[::-1]\n",
    "    return [srtArg,srt]\n",
    "\n",
    "similarity = evaluateSimilarity(tfidf.T[0],tfidf.T[1:4,])\n",
    "\n",
    "print('Similarities Rank:',similarity[0])\n",
    "print('Similarities:',similarity[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The similarities are [0.95469481 0.64317528 0.62890671] in the log base of 2\n",
    "\n",
    "## The ranks of docs are 2 3 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Precision  and  recall\n",
    "There is a database of 10000 images and a user, who is only interested in images which contain a car. It is known that there are 500 such images in the database. An  automatic image retrieval system retrieves 300 car images and 50 other images from the database. Determine and report the precision and recall of the retrieval  system in this particularcase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here:\n",
    "\n",
    "Precision=TP/(TP+FP)=$300/500=0.6$\n",
    "\n",
    "Recall=TP/(TP+TF)=$300/(300+50)=0.857$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - VGG practical on object instance recognition\n",
    "See the questions in part[1-3].ipynb and write your answers here.\n",
    "\n",
    "Part1:\n",
    "Stage I.A (two questions)\n",
    "Stage I.B (two questions)\n",
    "Stage I.C (one question)\n",
    "\n",
    "Part2 (one question)\n",
    "\n",
    "Part3:\n",
    "Stage III.A (three questions)\n",
    "Stage III.B (one question)\n",
    "Stage III.C (two questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answers here: \n",
    "\n",
    "# Part1\n",
    "\n",
    "## A1: \n",
    "### Becasue there is an area of shade in the left side of the second picture, causes the different density of detections. we find key points in pictures through calculation of guassian difference in SITF, mainly focusing on features like edges of bulidings and windows. So the shade didn't influential affect the matching.\n",
    "## A2\n",
    "### The keypoint orientation is determined from the local image appearance and is covariant to image rotations. Depending on the symmetry of the keypoint appearance, determining the orientation can be ambiguous. When the image feature is not on one single plane, Unrealistic results may be calculated by guassian function. \n",
    "\n",
    "## B1\n",
    "###  The descriptors is highly distinctive and invariant as possible to variations such as changes in viewpoint and illumination. To do this, a 16x16 window around the keypoint is taken. It is divided into 16 sub-blocks of 4x4 size. For each sub-block, 8 bin orientation histogram is created, so 4 X 4 descriptors over 16 X 16 sample array were used in practice. It is represented as a feature vector to form keypoint descriptor. Thus the descriptors are computed over a much larger region than the detection.\n",
    "## B2\n",
    "### I think lighting is not a problem here,because in SITF The result is highly distinctive and invariant as possible to variations such as changes in viewpoint and illumination as mentioned before. The reason of mismatch I think is too many high dimensional features at one time.\n",
    "\n",
    "## C1\n",
    "### RANSAC-like algorithm for geometric verification can be used in improving the mismatch in Section D. After this algorithm the inliers are consistent with the transformation and are retained, and most mismatches should now be removed.\n",
    "\n",
    "# Part2\n",
    "\n",
    "# Part3\n",
    "## A1\n",
    "\n",
    "## A2\n",
    "### because the time required to convert the descriptors into visual words can be precomputed for the images in database, so they don't account into total time.\n",
    "## A3\n",
    "\n",
    "## B1\n",
    "### There are 25 images counted in the result. The score is 1 because the qury image is the same as the first image.\n",
    "## C1\n",
    "### In code we can see newScore = len(inliers_word), the score are number of inliners_word.\n",
    "## C2\n",
    "\n",
    "### the dismatching images like different buildings and tourists now receive lower scores, so I think the results improved after geometric verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
